# Mediapipe American Sign Language Translator

This repository leverages the Mediapipe Holistic model to detect basic American Sign Language (ASL) gestures in real-time. The detected gestures are then translated into a sentence using the LLaMA translation model.

Dependencies

Ensure you have the required dependencies installed before running the program:

    OpenCV
    Mediapipe
    NumPy
    LLaMA (Local Language Model for ASL)


# Usage

1: Clone the repository:

    git clone https://github.com/kaifanyu/ASL_LTSM_Detection.git
    cd ASL_LTSM_Detection 

2: 

# Acknowledgements
- This program uses the Mediapipe library for holistic gesture recognition
- The translation model is powereed by LLaMA
